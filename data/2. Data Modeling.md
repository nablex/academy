# Data Modeling

Suppose you want to model a company with its employees. Depending on your background, you might instinctively model this in a hierarchical way:

[:.resources/hierarchical-company.png]

One company has multiple employees, so employee is a child of the company. When you are dealing with document structures (like XML, JSON,...) and document stores like some NoSQL databases, this is the way to go.

However, we use relational databases to store this data, at which point you need to "flatten" the data structures and express the relations between them with foreign keys. For example the same company could look like this in a relational model:

[:.resources/relational-company.png]

Note that both data structures are now separate, have gained an id field (the primary key) and that the employee now has an additional field which contains the company id. This companyId field will have a foreign key to the id field of the company, guaranteeing that the company can not be accidently deleted as long as there are employees attached to it.

This type of relation is what we call a "1-many" where one company can have multiple employees but each employee has exactly one company. We traditionally model this by adding the id of the "1" to the table of the "many".

Another type of relation is a "1-1", for example a resident in a country has exactly one passport for that country and that passport belongs to exactly one resident. In such a scenario you can choose in which part of the relation the foreign key is stored.

A special type of relation which is impossible to cleanly express in a hierarchical data model is "many-many". For example you can like multiple songs on spotify, but multiple people can like that same song. At this point it is no longer enough to have the id in one of the two tables, instead you need a third table to model this:

[:.resources/many-to-many.png]

## Extensions

Where foreign key relations are focused on "has" relationships, for example a company "has" employees, a resident "has" a passport, extensions are focused on "is" relationships.

For example suppose you are modelling a "pharmacy" and a "retailer". Both are separate types of entities with specific fields. However, one could argue that they are both organisations and as organisations they share a bunch of properties. Every pharmacy _is_ an organisation, every retailer _is_ an organisation.

We can model this type of relationship with extensions: pharmacy extends organisation which gives it all the fields organisation has plus some specific ones for pharmacy. Retailer likewise extends organisation.

Once you start with extensions at the data model level, you can choose (at the database level) how you store them:

- shared table: in this example we can go for three tables: we have an organisation table which has an entry for every pharmacy _and_ every retailer storing their common fields. We have two separate tables, one for pharmacy and one for retailer which store their respective additional fields. The extension tables have a foreign key reference to the shared table to ensure consistency.
- seperate tables: pharmacy has its own table which contains all the organisation fields plus its own fields, retailer has an unrelated table which has all the organisation fields and its own fields.

The first design has the benefit of being able to do searches on the organisation without specifically needing to know (or care) whether it is a pharmacy or a retailer.
The second design has the benefit that selects on pharmacies for example are not impacted by the retailers. This can be especially important when one or both of the extensions are considered high volume data. 

In most cases the first design (the three table approach) is the best solution.

The extension table will need a foreign key to the table it is extending, in a lot of cases it is modelled like this:

[:.resources/classic-extension.png]

Where the pharmacy (the one who extends) refers to the organisation (the one who is extended) by a separate field with a foreign key. 

However, if you use uuids as your primary keys, there is another option where the id of the pharmacy is the same value (and foreign key) to the id of the organisation:

[:.resources/custom-extension.png]

This way we don't need an additional field. It simplifies some operations, for example with a single id, you can query any of the tables without having to join them.

Because we almost always use uuids and this little optimization has a lot of added benefits, we will almost always opt for this solution.

### Nabu Extensions

Nabu supports extensions in all the supported model types (UML, XML Schema,...) and in the reference implementation of structures as well. Structures can go even further and you can for example create a structure that extends something defined in one of the other model types, for example a java bean.

However, you should explicitly tell Nabu how you want the data to be persisted, it will still work if you don't, but Nabu will be operating under some assumptions.

There is a property "collection name" that allows you to specify what the table name is for a complex type. The value in this field can (and should for consistency) also be camel case and it will undergo the same rewriting as the fields.

Not only does Nabu know what the table name is at that point, it also explicitly states which part of the extension you want to split off into a separate table.

For example suppose we have a "pharmacy" which extends "organisation". If we do nothing else and ask Nabu to persist it, it will be done in a single table called "pharmacy". The name is derived from the name of the root element, the extension is assumed to be stored in a single table rather than separate tables.

If we fill in the collection name for both the pharmacy and the organisation and check again how Nabu would model the data for pharmacy, you will see that it will only take the specific pharmacy extension fields, it now assumes the other data resides in the organisation table.

This is already close to what we want, one more thing however is that we want the id field to exist in both tables so we have a valid primary key. In all modeling languages, names are however unique among siblings, so you can not define the id field twice. Instead you have to tell Nabu to duplicate that field into pharmacy. Once you do this, we get the database layout we want.

[^.resources/extension-modeling.mp4]

In some cases we also duplicate metadata fields like 'created' and 'modified' in extension tables. Nabu will make sure these copied values are correctly kept in sync when inserting or updating.

### Nabu Database Handling

When generating selects, Nabu allows you to switch between the "all fields in one table" vs "multiple tables":

[^.resources/join-select.mp4]

When using a jdbc service for inserts, updates and delete statements it is however not possible to insert into multiple tables or update multiple tables at once. For that reason it is better to use the generic ``nabu.services.jdbc.Services`` services. You can give them instances of extensions and Nabu will make sure that the data is correctly persisted cross-table.

### Nabu Restrictions

A very specific type of extension is one where you _restrict_ what you inherit from your parent type. This is generally not supported by most modeling environments. However, XML Schema does have support for it and so does Nabu when it comes to structures.

A restrict property can be filled in with a comma separated list of fields you don't want to inherit:

[^.resources/restrict.mp4]

You _can_ at that point redefine that field as something entirely else, though this might be confusing and can give weird results when mapping data without taking this into account, so we generally don't do this.

**Important**: restrictions are a _very_ handy tool, but **not** for database models. If you for example have pharmacy extend organisation and restrict a mandatory field, the database will still expect it and inserts will _not_ work.

So why would you use these restrictions?

On the database end we gravitate towards overcapturing rather than undercapturing: often more is better. However, at the external communication end (for example when we expose data via API's or to a web application frontend), the reverse is true: the less data you need to send, the better!

However, for reasons outlined in the next chapter of this article, it makes things a lot easier if you can keep the data structures used in your API in sync as much as possible with how the data is modelled in the database. So allowing you to extend your original data model, then restrict it for external communication offers the best of both worlds.

# Evolving the data model

Applications are rarely "finished", usually new insights lead to new feature requests. This means having a robust way to evolve your data model is a real bonus.

Suppose you simply add a field to your data model, what exactly is impacted? You might need to change business logic that does some calculations with that data, this is one of the steps we can't automate away. However, all the mappings you do transferring data from one instance to another, all the statements concerned with selecting and persisting data or passing that data to the frontend via API's so it can be consumed in screens, all those things we _can_ automatically update by following a few simple rules.

For example suppose you have this select:

```sql
select
	o.id,
	o.vat,
	p.licensee
from ~organisations o join ~pharmacies p on p.id = o.id
```

The output of the select is the pharmacy we modelled in the above, which derives directly from the data model. If you add a field to the pharmacy, e.g. `publicName`, the output will be updated (as it directly references the model), but the SQL statement will not. This means best case the jdbc service fails because the output data model no longer matches the return value from the database or worst case, it silently keeps working but does not select the new data.

That means, if you add a field, you would need to update all your select statements. Additionally if you are using insert and update sql statements, those would need to be updated as well.

You can write this select slightly differently though to make sure it continues working as you update your data model:

```sql
select *
from ~organisations o join ~pharmacies p on p.id = o.id
```

At runtime, Nabu will expand the star into the correct columns based on the table information it has. Note that this **does** assume that the output document is correctly annotated to have all the necessary information. If your output document is either the data model itself or an extension thereof, it will automatically be correctly annotated. 

This means we can add (or even remove) fields, this select will keep on working.

Some things to keep in mind:

- use the generic insert/update/delete/merge services ``nabu.services.jdbc.Services`` rather than dedicated insert/update/... jdbc services. Not only is this more intelligent (e.g. inserts into multiple tables), it is also more future proof as you don't have hardcoded insert statements where new columns would not be automatically added or removed columns would persist.
- as mentioned in the example above: write selects using the * syntax rather than writing out the fields.
- use extensions and restrictions rather than duplicate document structures, extensions and restrictions are automatically updated as your core model changes, duplicate documents have to be manually kept in sync
- map documents at the root whenever possible rather than seperate lines

This last one might require a bit more explanation. Suppose we want to map all the fields of our pharmacy (for example for an outgoing API call). We could draw one line at a time for each field. However, if you add a new field, you would need to go back to that mapping and manually add a new line for the new field.

If however, we map at the root of the structure, it doesn't matter how many fields it has, they will all be mapped. If on the left side you have your full pharmacy data model and on the right side a limited set of fields you want to expose to the outside world, and this document is modeled via restrictions, you can simply add the field to your data model and everything will keep working. The "default" setting is however to also send that new field to the outside world. If you don't want that, update your list of restrictions, the mapping will keep on working either way.

[^.resources/root-mapping.mp4]

If two types are related through extension, you can draw a regular line as Nabu Developer knows they are related. If they are unrelated, you can draw a masked line. You can drag the line as you would normally and hold control. At that point the line becomes red when you drop it. This allows completely unrelated types to be mapped automatically by name.

# Miscellaneous

There are some other smaller topics that are related to data modeling and storage.

## CRUD

By far the most common actions on data can be described as CRUD: create, read, update, delete. In sql terminology: insert, select, update, delete.

With the conventions laid out above, you can do CRUD actions that don't break the minute you update the data model. All these conventions are also captured in the CRUD provider. This is a type of artifact where you hand it a data model and it will generate services that work in the background according to the conventions.

You can add restrictions by checking the fields you want to hide, add filters that will create dynamic select statements when needed and the resulting services that are available in the tree can be called directly or can be added to a web application as they are also valid REST services:

[^.resources/crud.mp4]

## Synchronization

You can generate DDL for a particular data structure or a folder of multiple data structures by ``Right Click -> SQL -> Create DDL -> <Database>`` where the database should be the type you will be using as the create syntax is generally specific per database. However, if you manage the DDL manually, you also have to manually make sure the DDL is executed in the correct environments at the correct time during deployment.

It's a lot easier to use the synchronize feature: ``Right Click -> SQL -> Synchronize -> To Database -> <Database>``. At this point the table will be created if it doesn't exist. When you deploy the code for the first time, the table will automatically be created in the target environment. When you change the model (e.g. add a column), the alter table scripts will be automatically run in every environment (upon deployment).

If you want to deploy DML (so actual data rather than table definitions), you can use deployment actions. When creating a deployment, the source service will be run to gather all the necessary data. After deployment the target service will be run which can then persist the necessary data. These deployment actions can be used for other things than DML though that is their primary use today.

For example for CMS related items, there are existing deployment actions that you can plug into your project, these automatically deploy things like masterdata, security settings, translations...

## Change Tracking

The SQL services and the generic services have a change tracker input field. You can fill in the implementation service of the change tracker specification. If you are using the CMS, you can use the default change tracker implementation: ``nabu.cms.core.providers.misc.changeTracker``.

When you enable change tracking on a particular insert, update or delete statement, Nabu will calculate _exactly_ what changed. For example if you run an update statement with 10 fields and only one actually differs from the one in the database, only that field is flagged. 

These changes are then sent to the change tracker who can choose to persist them. The CMS does this in a generic table where you can view all the changes that occurred to a table over time.

This, especially combined with other auditing options can give you a full overview of who changed what, when, through which action etc. You can generate timelines of how specific fields or entire tables evolved over time.

## Translations

Translations have a lot of dimensions, but of particular interest here is translations of operational content (as opposed to fixed copy in for example your website). For example imagine you are hosting a blog and want one article to be available in multiple languages.

Nabu can handle this automatically if you use the language inputs available in update and select statements. If you fill in the language input for an update statement, Nabu will check if the update is in the "default" language. If it is the default language, the update is performed on the table as any update normally would be. If it is not the default language however, Nabu will calculate what is different from this data as compared to the data in the actual table at that point and store these changes in a translation table assuming that the modified fields are translations of the original field values. 

Upon select, you can then fill in the language you want to select the data in, Nabu will select from the core table and automatically enrich that content with available translations for the selected language.

Once again the CMS has default providers for this.

## Affixes

In the generated statements you might have noticed that table names are generally prefixed with "~". This can actually occur before or after the table name but is generally put in the front. In most cases, the sign is removed before the SQL is executed. However, if you fill in the affix configuration in the JDBC connection that is being used, this can change. 

Suppose for example you want to use the task framework which has pretty generic table names like "tasks". These table names might conflict with your own already existing tables. At that point you could fill in the affix to for example "nabu_". From that point on, the task framework will automatically use the table "nabu_tasks", avoiding naming conflicts.

